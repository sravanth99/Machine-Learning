{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper modules\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    def __init__(self,estimator,k_features,scoring = accuracy_score,test_size = 0.2,random_state = 0):\n",
    "        self.estimator = clone(estimator) # cloning the learning algo / estimator ex : LogisticRegression\n",
    "        self.k_features = k_features #Number of features in the feature subset\n",
    "        self.scoring = scoring #criteria to select best feature subset combination\n",
    "        self.test_size = test_size # test size\n",
    "        self.random_state = random_state # random state\n",
    "    def fit(self,X,Y):\n",
    "        assert(X.shape[0]==Y.shape[0]) # debugging checking if X,Y have same number of rows ( instances )\n",
    "        '''Splitting data into train and test data to evaluate the accuracy'''\n",
    "        X_train,X_test,y_train,y_test = tts(X,Y,test_size = self.test_size,random_state = self.random_state,stratify = Y)\n",
    "        dim = X_train.shape[1] # Actual number of features\n",
    "        self.indices_ = tuple(range(dim)) # tuple of feature combinations\n",
    "        self.subsets_ = [self.indices_] # subset of preceeding tuple\n",
    "        score = self._return_score(X_train,y_train,X_test,y_test,self.indices_) #score for the indices combination\n",
    "        self.scores_ = [score] # list of scores\n",
    "        self.dim_ = [] #list to store different dimensions\n",
    "        while dim > self.k_features:\n",
    "            scores = [] # One each iteration starts with empty list\n",
    "            subsets = []\n",
    "            self.dim_.append(dim) # each dim is added to the dim_ list \n",
    "            for p in combinations(self.indices_,r=dim-1):\n",
    "                score = self._return_score(X_train,y_train,X_test,y_test,p) #score for every combination of k features.\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            best = np.argmax(scores) #index of the maximum score\n",
    "            self.indices_ = subsets[best] #combination of k features yielding best results.\n",
    "            self.subsets_.append(self.indices_)\n",
    "            self.scores_.append(scores[best])\n",
    "            self._k_score = self.scores_[-1]\n",
    "            dim -= 1 \n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[:,self.indices_] # returning data with best combination of desired number of features\n",
    "    def _return_score(self,X_train,y_train,X_test,y_test,indices): # evaluation function returns scores\n",
    "        self.estimator.fit(X_train[:,indices],y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:,indices])\n",
    "        score = self.scoring(y_test,y_pred)\n",
    "        return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
